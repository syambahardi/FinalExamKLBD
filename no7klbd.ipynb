{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNL/rnCrTAiD+GSga3EB8DO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/syambahardi/274f3cc6aa24fe3088eaf4439a415add/no7klbd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPJpI3CyDBX-",
        "outputId": "529bdaab-6a93-4800-d3d5-77560085791d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-04 09:12:17--  https://github.com/nzhinusoftcm/review-on-collaborative-filtering/raw/master/recsys.zip\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/nzhinusoftcm/review-on-collaborative-filtering/master/recsys.zip [following]\n",
            "--2023-01-04 09:12:17--  https://raw.githubusercontent.com/nzhinusoftcm/review-on-collaborative-filtering/master/recsys.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15312323 (15M) [application/zip]\n",
            "Saving to: ‘recsys.zip’\n",
            "\n",
            "recsys.zip          100%[===================>]  14.60M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-01-04 09:12:17 (276 MB/s) - ‘recsys.zip’ saved [15312323/15312323]\n",
            "\n",
            "Archive:  recsys.zip\n",
            "   creating: recsys/\n",
            "  inflating: recsys/datasets.py      \n",
            "  inflating: recsys/preprocessing.py  \n",
            "  inflating: recsys/utils.py         \n",
            "  inflating: recsys/requirements.txt  \n",
            "   creating: recsys/.vscode/\n",
            "  inflating: recsys/.vscode/settings.json  \n",
            "   creating: recsys/__pycache__/\n",
            "  inflating: recsys/__pycache__/datasets.cpython-36.pyc  \n",
            "  inflating: recsys/__pycache__/datasets.cpython-37.pyc  \n",
            "  inflating: recsys/__pycache__/utils.cpython-36.pyc  \n",
            "  inflating: recsys/__pycache__/preprocessing.cpython-37.pyc  \n",
            "  inflating: recsys/__pycache__/datasets.cpython-38.pyc  \n",
            "  inflating: recsys/__pycache__/preprocessing.cpython-36.pyc  \n",
            "  inflating: recsys/__pycache__/preprocessing.cpython-38.pyc  \n",
            "   creating: recsys/memories/\n",
            "  inflating: recsys/memories/ItemToItem.py  \n",
            "  inflating: recsys/memories/UserToUser.py  \n",
            "   creating: recsys/memories/__pycache__/\n",
            "  inflating: recsys/memories/__pycache__/UserToUser.cpython-36.pyc  \n",
            "  inflating: recsys/memories/__pycache__/UserToUser.cpython-37.pyc  \n",
            "  inflating: recsys/memories/__pycache__/ItemToItem.cpython-37.pyc  \n",
            "  inflating: recsys/memories/__pycache__/user2user.cpython-36.pyc  \n",
            "  inflating: recsys/memories/__pycache__/ItemToItem.cpython-36.pyc  \n",
            "   creating: recsys/models/\n",
            "  inflating: recsys/models/SVD.py    \n",
            "  inflating: recsys/models/MatrixFactorization.py  \n",
            "  inflating: recsys/models/ExplainableMF.py  \n",
            "  inflating: recsys/models/NonnegativeMF.py  \n",
            "   creating: recsys/models/__pycache__/\n",
            "  inflating: recsys/models/__pycache__/SVD.cpython-36.pyc  \n",
            "  inflating: recsys/models/__pycache__/MatrixFactorization.cpython-37.pyc  \n",
            "  inflating: recsys/models/__pycache__/ExplainableMF.cpython-36.pyc  \n",
            "  inflating: recsys/models/__pycache__/ExplainableMF.cpython-37.pyc  \n",
            "  inflating: recsys/models/__pycache__/MatrixFactorization.cpython-36.pyc  \n",
            "   creating: recsys/metrics/\n",
            "  inflating: recsys/metrics/EvaluationMetrics.py  \n",
            "   creating: recsys/img/\n",
            "  inflating: recsys/img/MF-and-NNMF.png  \n",
            "  inflating: recsys/img/svd.png      \n",
            "  inflating: recsys/img/MF.png       \n",
            "   creating: recsys/predictions/\n",
            "   creating: recsys/predictions/item2item/\n",
            "   creating: recsys/weights/\n",
            "   creating: recsys/weights/item2item/\n",
            "   creating: recsys/weights/item2item/ml1m/\n",
            "  inflating: recsys/weights/item2item/ml1m/similarities.npy  \n",
            "  inflating: recsys/weights/item2item/ml1m/neighbors.npy  \n",
            "   creating: recsys/weights/item2item/ml100k/\n",
            "  inflating: recsys/weights/item2item/ml100k/similarities.npy  \n",
            "  inflating: recsys/weights/item2item/ml100k/neighbors.npy  \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "if not (os.path.exists(\"recsys.zip\") or os.path.exists(\"recsys\")):\n",
        "    !wget https://github.com/nzhinusoftcm/review-on-collaborative-filtering/raw/master/recsys.zip    \n",
        "    !unzip recsys.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from recsys.memories.UserToUser import UserToUser\n",
        "\n",
        "from recsys.preprocessing import mean_ratings\n",
        "from recsys.preprocessing import normalized_ratings\n",
        "from recsys.preprocessing import ids_encoder\n",
        "from recsys.preprocessing import train_test_split\n",
        "from recsys.preprocessing import rating_matrix\n",
        "from recsys.preprocessing import get_examples\n",
        "\n",
        "from recsys.datasets import ml100k, ml1m\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import sys\n",
        "import os"
      ],
      "metadata": {
        "id": "Qo-uVbShDn8_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def explainable_score(user2user, users, items, theta=0):\n",
        "    \n",
        "    def _progress(count):\n",
        "        sys.stdout.write('\\rCompute Explainable score. Progress status : %.1f%%'%(float(count/len(users))*100.0))\n",
        "        sys.stdout.flush()\n",
        "    # initialize explainable score to zeros\n",
        "    W = np.zeros((len(users), len(items)))\n",
        "\n",
        "    for count, u in enumerate(users):            \n",
        "        candidate_items = user2user.find_user_candidate_items(u)        \n",
        "        for i in candidate_items:                \n",
        "            user_who_rated_i, similar_user_who_rated_i = \\\n",
        "                user2user.similar_users_who_rated_this_item(u, i)\n",
        "            if user_who_rated_i.shape[0] == 0:\n",
        "                w = 0.0\n",
        "            else:\n",
        "                w = similar_user_who_rated_i.shape[0] / user_who_rated_i.shape[0]\n",
        "            W[u,i] =  w  if w > theta else 0.0\n",
        "        _progress(count)\n",
        "    return W"
      ],
      "metadata": {
        "id": "X1Jud7FyDq5s"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ExplainableMatrixFactorization:\n",
        "    \n",
        "    def __init__(self, m, n, W, alpha=0.001, beta=0.01, lamb=0.1, k=10):\n",
        "        \"\"\"\n",
        "            - R : Rating matrix of shape (m,n) \n",
        "            - W : Explainability Weights of shape (m,n)\n",
        "            - k : number of latent factors\n",
        "            - beta : L2 regularization parameter\n",
        "            - lamb : explainability regularization coefficient\n",
        "            - theta : threshold above which an item is explainable for a user\n",
        "        \"\"\"\n",
        "        self.W = W\n",
        "        self.m = m\n",
        "        self.n = n\n",
        "        \n",
        "        np.random.seed(64)\n",
        "        \n",
        "        # initialize the latent factor matrices P and Q (of shapes (m,k) and (n,k) respectively) that will be learnt\n",
        "        self.k = k\n",
        "        self.P = np.random.normal(size=(self.m,k))\n",
        "        self.Q = np.random.normal(size=(self.n,k))\n",
        "        \n",
        "        # hyperparameter initialization\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.lamb = lamb\n",
        "        \n",
        "        # training history\n",
        "        self.history = {\n",
        "            \"epochs\":[],\n",
        "            \"loss\":[],\n",
        "            \"val_loss\":[],\n",
        "        }\n",
        "        \n",
        "    def print_training_parameters(self):\n",
        "        print('Training EMF')\n",
        "        print(f'k={self.k} \\t alpha={self.alpha} \\t beta={self.beta} \\t lambda={self.lamb}')\n",
        "        \n",
        "    def update_rule(self, u, i, error):\n",
        "        self.P[u] = self.P[u] + \\\n",
        "            self.alpha*(2 * error*self.Q[i] - self.beta*self.P[u] - self.lamb*(self.P[u] - self.Q[i]) * self.W[u,i])\n",
        "        \n",
        "        self.Q[i] = self.Q[i] + \\\n",
        "            self.alpha*(2 * error*self.P[u] - self.beta*self.Q[i] + self.lamb*(self.P[u] - self.Q[i]) * self.W[u,i])\n",
        "        \n",
        "    def mae(self,  x_train, y_train):\n",
        "        \"\"\"\n",
        "        returns the Mean Absolute Error\n",
        "        \"\"\"\n",
        "        # number of training exemples\n",
        "        M = x_train.shape[0]\n",
        "        error = 0\n",
        "        for pair, r in zip(x_train, y_train):\n",
        "            u, i = pair\n",
        "            error += np.absolute(r - np.dot(self.P[u], self.Q[i]))\n",
        "        return error/M\n",
        "    \n",
        "    def print_training_progress(self, epoch, epochs, error, val_error, steps=5):\n",
        "        if epoch == 1 or epoch % steps == 0 :\n",
        "                print(f\"epoch {epoch}/{epochs} - loss : {round(error,3)} - val_loss : {round(val_error,3)}\")\n",
        "                \n",
        "    def learning_rate_schedule(self, epoch, target_epochs = 20):\n",
        "        if (epoch >= target_epochs) and (epoch % target_epochs == 0):\n",
        "                factor = epoch // target_epochs\n",
        "                self.alpha = self.alpha * (1 / (factor * 20))\n",
        "                print(\"\\nLearning Rate : {}\\n\".format(self.alpha))\n",
        "        \n",
        "    def fit(self, x_train, y_train, validation_data, epochs=10):\n",
        "        \"\"\"\n",
        "        Train latent factors P and Q according to the training set\n",
        "        \n",
        "        :param\n",
        "            - x_train : training pairs (u,i) for which rating r_ui is known\n",
        "            - y_train : set of ratings r_ui for all training pairs (u,i)\n",
        "            - validation_data : tuple (x_test, y_test)\n",
        "            - epochs : number of time to loop over the entire training set. \n",
        "            10 epochs by default\n",
        "            \n",
        "        Note that u and i are encoded values of userid and itemid\n",
        "        \"\"\"\n",
        "        self.print_training_parameters()\n",
        "        \n",
        "        # get validation data\n",
        "        x_test, y_test = validation_data\n",
        "        \n",
        "        for epoch in range(1, epochs+1):\n",
        "            for pair, r in zip(x_train, y_train):                \n",
        "                u,i = pair                \n",
        "                r_hat = np.dot(self.P[u], self.Q[i])                \n",
        "                e = r - r_hat\n",
        "                self.update_rule(u, i, error=e)\n",
        "                \n",
        "            # training and validation error  after this epochs\n",
        "            error = self.mae(x_train, y_train)\n",
        "            val_error = self.mae(x_test, y_test)\n",
        "            self.update_history(epoch, error, val_error)            \n",
        "            self.print_training_progress(epoch, epochs, error, val_error, steps=1)\n",
        "        \n",
        "        return self.history\n",
        "    \n",
        "    def update_history(self, epoch, error, val_error):\n",
        "        self.history['epochs'].append(epoch)\n",
        "        self.history['loss'].append(error)\n",
        "        self.history['val_loss'].append(val_error)\n",
        "    \n",
        "    def evaluate(self, x_test, y_test):\n",
        "        \"\"\"\n",
        "        compute the global error on the test set\n",
        "        \n",
        "        :param\n",
        "            - x_test : test pairs (u,i) for which rating r_ui is known\n",
        "            - y_test : set of ratings r_ui for all test pairs (u,i)\n",
        "        \"\"\"\n",
        "        error = self.mae(x_test, y_test)\n",
        "        print(f\"validation error : {round(error,3)}\")\n",
        "      \n",
        "    def predict(self, userid, itemid):\n",
        "        \"\"\"\n",
        "        Make rating prediction for a user on an item\n",
        "\n",
        "        :param\n",
        "        - userid\n",
        "        - itemid\n",
        "\n",
        "        :return\n",
        "        - r : predicted rating\n",
        "        \"\"\"\n",
        "        # encode user and item ids to be able to access their latent factors in\n",
        "        # matrices P and Q\n",
        "        u = uencoder.transform([userid])[0]\n",
        "        i = iencoder.transform([itemid])[0]\n",
        "\n",
        "        # rating prediction using encoded ids. Dot product between P_u and Q_i\n",
        "        r = np.dot(self.P[u], self.Q[i])\n",
        "\n",
        "        return r\n",
        "\n",
        "    def recommend(self, userid, N=30):\n",
        "        \"\"\"\n",
        "        make to N recommendations for a given user\n",
        "\n",
        "        :return \n",
        "        - (top_items,preds) : top N items with the highest predictions \n",
        "        \"\"\"\n",
        "        # encode the userid\n",
        "        u = uencoder.transform([userid])[0]\n",
        "\n",
        "        # predictions for this user on all product\n",
        "        predictions = np.dot(self.P[u], self.Q.T)\n",
        "\n",
        "        # get the indices of the top N predictions\n",
        "        top_idx = np.flip(np.argsort(predictions))[:N]\n",
        "\n",
        "        # decode indices to get their corresponding itemids\n",
        "        top_items = iencoder.inverse_transform(top_idx)\n",
        "\n",
        "        # take corresponding predictions for top N indices\n",
        "        preds = predictions[top_idx]\n",
        "\n",
        "        return top_items, preds"
      ],
      "metadata": {
        "id": "HOpp8oFhDuSA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10"
      ],
      "metadata": {
        "id": "LADvVqQxDyLm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "ratings, movies = ml100k.load()\n",
        "\n",
        "# encode users and items ids\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "users = sorted(ratings.userid.unique())\n",
        "items = sorted(ratings.itemid.unique())\n",
        "\n",
        "m = len(users)\n",
        "n = len(items)\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings)\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKzB5koCD0Ln",
        "outputId": "a35f6bf0-48e5-42c1-d3a1-91c79378b1f6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download data 100.2%\n",
            "Successfully downloaded ml-100k.zip 4924029 bytes.\n",
            "Unzipping the ml-100k.zip zip file ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the user to user model for similarity measure\n",
        "usertouser = UserToUser(ratings, movies)\n",
        "\n",
        "# compute explainable score\n",
        "W = explainable_score(usertouser, users, items)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf990-JGD3Lo",
        "outputId": "fab42036-755f-4596-80b1-d6409fbeb4ad"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalize users ratings ...\n",
            "Initialize the similarity model ...\n",
            "Compute nearest neighbors ...\n",
            "User to user recommendation model created with success ...\n",
            "Compute Explainable score. Progress status : 99.9%"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the model\n",
        "EMF = ExplainableMatrixFactorization(m, n, W, alpha=0.01, beta=0.4, lamb=0.01, k=10)\n",
        "\n",
        "history = EMF.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xgeck6dnEK4t",
        "outputId": "174860ab-7649-4edc-8765-23206e291214"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training EMF\n",
            "k=10 \t alpha=0.01 \t beta=0.4 \t lambda=0.01\n",
            "epoch 1/10 - loss : 0.922 - val_loss : 1.036\n",
            "epoch 2/10 - loss : 0.79 - val_loss : 0.873\n",
            "epoch 3/10 - loss : 0.766 - val_loss : 0.837\n",
            "epoch 4/10 - loss : 0.757 - val_loss : 0.822\n",
            "epoch 5/10 - loss : 0.753 - val_loss : 0.814\n",
            "epoch 6/10 - loss : 0.751 - val_loss : 0.808\n",
            "epoch 7/10 - loss : 0.749 - val_loss : 0.805\n",
            "epoch 8/10 - loss : 0.748 - val_loss : 0.802\n",
            "epoch 9/10 - loss : 0.746 - val_loss : 0.799\n",
            "epoch 10/10 - loss : 0.745 - val_loss : 0.797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMF.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4j5OhA93EanH",
        "outputId": "f31d6b4b-f2c8-40b6-d2c2-cd2332952504"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation error : 0.797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "ratings, movies = ml100k.load()\n",
        "\n",
        "# encode users and items ids\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "users = sorted(ratings.userid.unique())\n",
        "items = sorted(ratings.itemid.unique())\n",
        "\n",
        "m = len(users)\n",
        "n = len(items)\n",
        "\n",
        "# normalize ratings by substracting means\n",
        "normalized_column_name = \"norm_rating\"\n",
        "ratings = normalized_ratings(ratings, norm_column=normalized_column_name)\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings, labels_column=normalized_column_name)\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)"
      ],
      "metadata": {
        "id": "Oawo1FdBEm0O"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the model\n",
        "EMF = ExplainableMatrixFactorization(m, n, W, alpha=0.022, beta=0.65, lamb=0.01, k=10)\n",
        "\n",
        "history = EMF.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryk1tcANFUdF",
        "outputId": "df411cc3-a660-49e7-9da9-d28aafc835fa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training EMF\n",
            "k=10 \t alpha=0.022 \t beta=0.65 \t lambda=0.01\n",
            "epoch 1/10 - loss : 0.809 - val_loss : 0.842\n",
            "epoch 2/10 - loss : 0.809 - val_loss : 0.829\n",
            "epoch 3/10 - loss : 0.807 - val_loss : 0.821\n",
            "epoch 4/10 - loss : 0.799 - val_loss : 0.811\n",
            "epoch 5/10 - loss : 0.789 - val_loss : 0.8\n",
            "epoch 6/10 - loss : 0.782 - val_loss : 0.793\n",
            "epoch 7/10 - loss : 0.778 - val_loss : 0.789\n",
            "epoch 8/10 - loss : 0.776 - val_loss : 0.786\n",
            "epoch 9/10 - loss : 0.774 - val_loss : 0.784\n",
            "epoch 10/10 - loss : 0.773 - val_loss : 0.783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "ratings, movies = ml1m.load()\n",
        "\n",
        "# encode users and items ids\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "users = sorted(ratings.userid.unique())\n",
        "items = sorted(ratings.itemid.unique())\n",
        "\n",
        "m = len(users)\n",
        "n = len(items)\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings)\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtjDxtiqGDl5",
        "outputId": "d1c3cd4b-9c81-45ef-af8e-15a779db368b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download data 100.1%\n",
            "Successfully downloaded ml-1m.zip 5917549 bytes.\n",
            "Unzipping the ml-1m.zip zip file ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the user to user model for similarity measure\n",
        "usertouser = UserToUser(ratings, movies)\n",
        "\n",
        "# compute explainable score\n",
        "W = explainable_score(usertouser, users, items)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C07nadf4GK-9",
        "outputId": "651ecb7f-2fbb-4b0e-ffd9-de28bce8c4a2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalize users ratings ...\n",
            "Initialize the similarity model ...\n",
            "Compute nearest neighbors ...\n",
            "User to user recommendation model created with success ...\n",
            "Compute Explainable score. Progress status : 100.0%"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the model\n",
        "EMF = ExplainableMatrixFactorization(m, n, W, alpha=0.01, beta=0.4, lamb=0.01, k=10)\n",
        "\n",
        "history = EMF.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLsF83kyLTdl",
        "outputId": "d0d94f7b-5b23-4819-fa1b-894335a1b08c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training EMF\n",
            "k=10 \t alpha=0.01 \t beta=0.4 \t lambda=0.01\n",
            "epoch 1/10 - loss : 0.782 - val_loss : 0.807\n",
            "epoch 2/10 - loss : 0.762 - val_loss : 0.781\n",
            "epoch 3/10 - loss : 0.76 - val_loss : 0.775\n",
            "epoch 4/10 - loss : 0.758 - val_loss : 0.771\n",
            "epoch 5/10 - loss : 0.757 - val_loss : 0.769\n",
            "epoch 6/10 - loss : 0.756 - val_loss : 0.767\n",
            "epoch 7/10 - loss : 0.754 - val_loss : 0.764\n",
            "epoch 8/10 - loss : 0.752 - val_loss : 0.762\n",
            "epoch 9/10 - loss : 0.751 - val_loss : 0.761\n",
            "epoch 10/10 - loss : 0.75 - val_loss : 0.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMF.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWOsFO4BQ5uM",
        "outputId": "442fcabd-efcd-46eb-aa9e-fbee65ce4b57"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation error : 0.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "ratings, movies = ml100k.load()\n",
        "\n",
        "# encode users and items ids\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "users = sorted(ratings.userid.unique())\n",
        "items = sorted(ratings.itemid.unique())\n",
        "\n",
        "m = len(users)\n",
        "n = len(items)\n",
        "\n",
        "# normalize ratings by substracting means\n",
        "normalized_column_name = \"norm_rating\"\n",
        "ratings = normalized_ratings(ratings, norm_column=normalized_column_name)\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings, labels_column=normalized_column_name)\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)"
      ],
      "metadata": {
        "id": "0MxqgtcTQ9ke"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the model\n",
        "EMF = ExplainableMatrixFactorization(m, n, W, alpha=0.022, beta=0.65, lamb=0.01, k=10)\n",
        "\n",
        "history = EMF.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tm0im2aRAjk",
        "outputId": "814f1031-cd2d-4c01-f527-d60c865e268b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training EMF\n",
            "k=10 \t alpha=0.022 \t beta=0.65 \t lambda=0.01\n",
            "epoch 1/10 - loss : 0.809 - val_loss : 0.842\n",
            "epoch 2/10 - loss : 0.809 - val_loss : 0.829\n",
            "epoch 3/10 - loss : 0.807 - val_loss : 0.821\n",
            "epoch 4/10 - loss : 0.799 - val_loss : 0.811\n",
            "epoch 5/10 - loss : 0.789 - val_loss : 0.8\n",
            "epoch 6/10 - loss : 0.782 - val_loss : 0.793\n",
            "epoch 7/10 - loss : 0.778 - val_loss : 0.789\n",
            "epoch 8/10 - loss : 0.776 - val_loss : 0.786\n",
            "epoch 9/10 - loss : 0.774 - val_loss : 0.784\n",
            "epoch 10/10 - loss : 0.773 - val_loss : 0.783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "ratings, movies = ml1m.load()\n",
        "\n",
        "# encode users and items ids\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "users = sorted(ratings.userid.unique())\n",
        "items = sorted(ratings.itemid.unique())\n",
        "\n",
        "m = len(users)\n",
        "n = len(items)\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings)\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)"
      ],
      "metadata": {
        "id": "w9mA84tURXyv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the user to user model for similarity measure\n",
        "usertouser = UserToUser(ratings, movies)\n",
        "\n",
        "# compute explainable score\n",
        "W = explainable_score(usertouser, users, items)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl_Yj7SxRcVT",
        "outputId": "792f258f-fc46-43f4-bc06-6bb0b994e028"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalize users ratings ...\n",
            "Initialize the similarity model ...\n",
            "Compute nearest neighbors ...\n",
            "User to user recommendation model created with success ...\n",
            "Compute Explainable score. Progress status : 100.0%"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the model\n",
        "EMF = ExplainableMatrixFactorization(m, n, W, alpha=0.01, beta=0.4, lamb=0.01, k=10)\n",
        "\n",
        "history = EMF.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yakYVJnWR5d",
        "outputId": "24cc4b85-2c1a-4228-bf6d-a7c7dd68e932"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training EMF\n",
            "k=10 \t alpha=0.01 \t beta=0.4 \t lambda=0.01\n",
            "epoch 1/10 - loss : 0.782 - val_loss : 0.807\n",
            "epoch 2/10 - loss : 0.762 - val_loss : 0.781\n",
            "epoch 3/10 - loss : 0.76 - val_loss : 0.775\n",
            "epoch 4/10 - loss : 0.758 - val_loss : 0.771\n",
            "epoch 5/10 - loss : 0.757 - val_loss : 0.769\n",
            "epoch 6/10 - loss : 0.756 - val_loss : 0.767\n",
            "epoch 7/10 - loss : 0.754 - val_loss : 0.764\n",
            "epoch 8/10 - loss : 0.752 - val_loss : 0.762\n",
            "epoch 9/10 - loss : 0.751 - val_loss : 0.761\n",
            "epoch 10/10 - loss : 0.75 - val_loss : 0.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "ratings, movies = ml1m.load()\n",
        "\n",
        "# encode users and items ids\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "# normalize ratings by substracting means\n",
        "normalized_column_name = \"norm_rating\"\n",
        "ratings = normalized_ratings(ratings, norm_column=normalized_column_name)\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings, labels_column=normalized_column_name)\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)"
      ],
      "metadata": {
        "id": "hy8SuAgLYmjJ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the model\n",
        "EMF = ExplainableMatrixFactorization(m, n, W, alpha=0.023, beta=0.59, lamb=0.01, k=10)\n",
        "\n",
        "history = EMF.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODajVROGaF6f",
        "outputId": "c0f47229-a352-487b-8809-2e9cd4f54211"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training EMF\n",
            "k=10 \t alpha=0.023 \t beta=0.59 \t lambda=0.01\n",
            "epoch 1/10 - loss : 0.805 - val_loss : 0.814\n",
            "epoch 2/10 - loss : 0.764 - val_loss : 0.77\n",
            "epoch 3/10 - loss : 0.756 - val_loss : 0.762\n",
            "epoch 4/10 - loss : 0.755 - val_loss : 0.759\n",
            "epoch 5/10 - loss : 0.754 - val_loss : 0.759\n",
            "epoch 6/10 - loss : 0.754 - val_loss : 0.758\n",
            "epoch 7/10 - loss : 0.754 - val_loss : 0.758\n",
            "epoch 8/10 - loss : 0.753 - val_loss : 0.758\n",
            "epoch 9/10 - loss : 0.753 - val_loss : 0.758\n",
            "epoch 10/10 - loss : 0.753 - val_loss : 0.758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get list of top N items with their corresponding predicted ratings\n",
        "userid = 42\n",
        "recommended_items, predictions = EMF.recommend(userid=userid)\n",
        "\n",
        "# find corresponding movie titles\n",
        "top_N = list(zip(recommended_items,predictions))\n",
        "top_N = pd.DataFrame(top_N, columns=['itemid','predictions'])\n",
        "top_N.predictions = top_N.predictions + ratings.loc[ratings.userid==userid].rating_mean.values[0]\n",
        "List = pd.merge(top_N, movies, on='itemid', how='inner')\n",
        "\n",
        "# show the list\n",
        "List"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "axepZCv9cypP",
        "outputId": "228ebc07-a2d7-414e-d6a0-d0b58793ae2b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    itemid  predictions                                              title  \\\n",
              "0     3460     4.364036               Hillbillys in a Haunted House (1967)   \n",
              "1      701     4.324177                                       Daens (1992)   \n",
              "2     3057     4.307404                            Where's Marlowe? (1999)   \n",
              "3     2214     4.304979                            Number Seventeen (1932)   \n",
              "4     1145     4.299559                                  Snowriders (1996)   \n",
              "5     2258     4.292125                              Master Ninja I (1984)   \n",
              "6     3353     4.281912                         Closer You Get, The (2000)   \n",
              "7      868     4.278937                          Death in Brunswick (1991)   \n",
              "8      826     4.269901                                   Diebinnen (1995)   \n",
              "9     3305     4.266769                                   Bluebeard (1944)   \n",
              "10    2619     4.265997                                     Mascara (1999)   \n",
              "11     763     4.264092  Last of the High Kings, The (a.k.a. Summer Fli...   \n",
              "12    1852     4.262517                              Love Walked In (1998)   \n",
              "13     642     4.260353                                       Roula (1995)   \n",
              "14     682     4.258829         Tigrero: A Film That Was Never Made (1994)   \n",
              "15     792     4.253339                     Hungarian Fairy Tale, A (1987)   \n",
              "16    1316     4.252915                                        Anna (1996)   \n",
              "17    3228     4.245526                              Wirey Spindell (1999)   \n",
              "18     853     4.240745                                       Dingo (1992)   \n",
              "19    3172     4.238188                            Ulysses (Ulisse) (1954)   \n",
              "20    2254     4.238008                                     Choices (1981)   \n",
              "21    2503     4.234547                            Apple, The (Sib) (1998)   \n",
              "22    2905     4.224974                                     Sanjuro (1962)   \n",
              "23     744     4.224278                         Brothers in Trouble (1995)   \n",
              "24     757     4.224226                               Ashes of Time (1994)   \n",
              "25     858     4.223665                              Godfather, The (1972)   \n",
              "26     789     4.220788      I, Worst of All (Yo, la peor de todas) (1990)   \n",
              "27    3748     4.216508                                  Match, The (1999)   \n",
              "28     790     4.216455                     An Unforgettable Summer (1994)   \n",
              "29     745     4.215986                              Close Shave, A (1995)   \n",
              "\n",
              "                       genres  \n",
              "0                      Comedy  \n",
              "1                       Drama  \n",
              "2                      Comedy  \n",
              "3                    Thriller  \n",
              "4                 Documentary  \n",
              "5                      Action  \n",
              "6              Comedy|Romance  \n",
              "7                      Comedy  \n",
              "8                       Drama  \n",
              "9            Film-Noir|Horror  \n",
              "10                      Drama  \n",
              "11                      Drama  \n",
              "12             Drama|Thriller  \n",
              "13                      Drama  \n",
              "14          Documentary|Drama  \n",
              "15                    Fantasy  \n",
              "16                      Drama  \n",
              "17                     Comedy  \n",
              "18                      Drama  \n",
              "19                  Adventure  \n",
              "20                      Drama  \n",
              "21                      Drama  \n",
              "22           Action|Adventure  \n",
              "23                      Drama  \n",
              "24                      Drama  \n",
              "25         Action|Crime|Drama  \n",
              "26                      Drama  \n",
              "27             Comedy|Romance  \n",
              "28                      Drama  \n",
              "29  Animation|Comedy|Thriller  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b54208d7-be24-48e3-80ae-f0d5b46908b5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>itemid</th>\n",
              "      <th>predictions</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3460</td>\n",
              "      <td>4.364036</td>\n",
              "      <td>Hillbillys in a Haunted House (1967)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>701</td>\n",
              "      <td>4.324177</td>\n",
              "      <td>Daens (1992)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3057</td>\n",
              "      <td>4.307404</td>\n",
              "      <td>Where's Marlowe? (1999)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2214</td>\n",
              "      <td>4.304979</td>\n",
              "      <td>Number Seventeen (1932)</td>\n",
              "      <td>Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1145</td>\n",
              "      <td>4.299559</td>\n",
              "      <td>Snowriders (1996)</td>\n",
              "      <td>Documentary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2258</td>\n",
              "      <td>4.292125</td>\n",
              "      <td>Master Ninja I (1984)</td>\n",
              "      <td>Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3353</td>\n",
              "      <td>4.281912</td>\n",
              "      <td>Closer You Get, The (2000)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>868</td>\n",
              "      <td>4.278937</td>\n",
              "      <td>Death in Brunswick (1991)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>826</td>\n",
              "      <td>4.269901</td>\n",
              "      <td>Diebinnen (1995)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3305</td>\n",
              "      <td>4.266769</td>\n",
              "      <td>Bluebeard (1944)</td>\n",
              "      <td>Film-Noir|Horror</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2619</td>\n",
              "      <td>4.265997</td>\n",
              "      <td>Mascara (1999)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>763</td>\n",
              "      <td>4.264092</td>\n",
              "      <td>Last of the High Kings, The (a.k.a. Summer Fli...</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1852</td>\n",
              "      <td>4.262517</td>\n",
              "      <td>Love Walked In (1998)</td>\n",
              "      <td>Drama|Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>642</td>\n",
              "      <td>4.260353</td>\n",
              "      <td>Roula (1995)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>682</td>\n",
              "      <td>4.258829</td>\n",
              "      <td>Tigrero: A Film That Was Never Made (1994)</td>\n",
              "      <td>Documentary|Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>792</td>\n",
              "      <td>4.253339</td>\n",
              "      <td>Hungarian Fairy Tale, A (1987)</td>\n",
              "      <td>Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1316</td>\n",
              "      <td>4.252915</td>\n",
              "      <td>Anna (1996)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>3228</td>\n",
              "      <td>4.245526</td>\n",
              "      <td>Wirey Spindell (1999)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>853</td>\n",
              "      <td>4.240745</td>\n",
              "      <td>Dingo (1992)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>3172</td>\n",
              "      <td>4.238188</td>\n",
              "      <td>Ulysses (Ulisse) (1954)</td>\n",
              "      <td>Adventure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2254</td>\n",
              "      <td>4.238008</td>\n",
              "      <td>Choices (1981)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2503</td>\n",
              "      <td>4.234547</td>\n",
              "      <td>Apple, The (Sib) (1998)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2905</td>\n",
              "      <td>4.224974</td>\n",
              "      <td>Sanjuro (1962)</td>\n",
              "      <td>Action|Adventure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>744</td>\n",
              "      <td>4.224278</td>\n",
              "      <td>Brothers in Trouble (1995)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>757</td>\n",
              "      <td>4.224226</td>\n",
              "      <td>Ashes of Time (1994)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>858</td>\n",
              "      <td>4.223665</td>\n",
              "      <td>Godfather, The (1972)</td>\n",
              "      <td>Action|Crime|Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>789</td>\n",
              "      <td>4.220788</td>\n",
              "      <td>I, Worst of All (Yo, la peor de todas) (1990)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>3748</td>\n",
              "      <td>4.216508</td>\n",
              "      <td>Match, The (1999)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>790</td>\n",
              "      <td>4.216455</td>\n",
              "      <td>An Unforgettable Summer (1994)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>745</td>\n",
              "      <td>4.215986</td>\n",
              "      <td>Close Shave, A (1995)</td>\n",
              "      <td>Animation|Comedy|Thriller</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b54208d7-be24-48e3-80ae-f0d5b46908b5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b54208d7-be24-48e3-80ae-f0d5b46908b5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b54208d7-be24-48e3-80ae-f0d5b46908b5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}